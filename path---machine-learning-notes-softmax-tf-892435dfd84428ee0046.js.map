{"version":3,"sources":["webpack:///path---machine-learning-notes-softmax-tf-892435dfd84428ee0046.js","webpack:///./.cache/json/machine-learning-notes-softmax-tf.json"],"names":["webpackJsonp","714","module","exports","data","markdownRemark","html","timeToRead","excerpt","frontmatter","title","cover","fields","nextTitle","nextSlug","prevTitle","prevSlug","slug","modifiedTime","allDirectory","allFile","pathContext","slugTrim"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,gBAAkBC,KAAA,msnBAAs5oBC,WAAA,EAAAC,QAAA,GAAAC,aAAmKC,MAAA,0BAAAC,MAAA,MAA+CC,QAAWC,UAAA,yBAAAC,SAAA,mCAAAC,UAAA,gCAAAC,SAAA,mDAAAC,KAAA,sCAAAC,aAAA,mBAA2QC,aAAA,KAAAC,QAAA,MAAoCC,aAAgBJ,KAAA,sCAAAK,SAAA","file":"path---machine-learning-notes-softmax-tf-892435dfd84428ee0046.js","sourcesContent":["webpackJsonp([252309606565646],{\n\n/***/ 714:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<div class=\\\"gatsby-highlight\\\">\\n      <pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token comment\\\"># Author: Fajar UN</span>\\n\\n<span class=\\\"token comment\\\"># Import MNIST data</span>\\n<span class=\\\"token comment\\\"># from tensorflow.examples.tutorials.mnist import input_data</span>\\n<span class=\\\"token comment\\\"># mnist = input_data.read_data_sets(\\\"/tmp/data/\\\", one_hot=True)</span>\\n\\n<span class=\\\"token keyword\\\">import</span> pandas <span class=\\\"token keyword\\\">as</span> pd\\ndf <span class=\\\"token operator\\\">=</span> pd<span class=\\\"token punctuation\\\">.</span>get_dummies<span class=\\\"token punctuation\\\">(</span>pd<span class=\\\"token punctuation\\\">.</span>read_csv<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'iris.csv'</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> columns<span class=\\\"token operator\\\">=</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'species'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>sample<span class=\\\"token punctuation\\\">(</span>frac<span class=\\\"token operator\\\">=</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span>\\nlabel_cols <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'species_setosa'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'species_versicolor'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'species_virginica'</span><span class=\\\"token punctuation\\\">]</span>\\n\\n\\nsplit_val <span class=\\\"token operator\\\">=</span> <span class=\\\"token builtin\\\">int</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> <span class=\\\"token number\\\">0.8</span><span class=\\\"token punctuation\\\">)</span>\\ntraining_input <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'sepal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'sepal_width'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_width'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">:</span>split_val<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\ntesting_input <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'sepal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'sepal_width'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_width'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span>split_val<span class=\\\"token punctuation\\\">:</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\ntraining_output <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span>label_cols<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">:</span>split_val<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\ntesting_output <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span>label_cols<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span>split_val<span class=\\\"token punctuation\\\">:</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token keyword\\\">import</span> tensorflow <span class=\\\"token keyword\\\">as</span> tf\\n\\n<span class=\\\"token comment\\\"># Parameters</span>\\nlearning_rate <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">0.001</span>\\ntraining_epochs <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">1000</span>\\nbatch_size <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">100</span>\\ndisplay_step <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">100</span>\\n\\n<span class=\\\"token comment\\\"># Network Parameters</span>\\nn_hidden_1 <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">6</span> <span class=\\\"token comment\\\"># 1st layer number of features</span>\\nn_hidden_2 <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">12</span> <span class=\\\"token comment\\\"># 2nd layer number of features</span>\\nn_input <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">4</span> <span class=\\\"token comment\\\"># MNIST data input (img shape: 28*28)</span>\\nn_classes <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">3</span> <span class=\\\"token comment\\\"># MNIST total classes (0-9 digits)</span>\\n\\n<span class=\\\"token comment\\\"># tf Graph input</span>\\nx <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>placeholder<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"float\\\"</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token boolean\\\">None</span><span class=\\\"token punctuation\\\">,</span> n_input<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\ny <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>placeholder<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"float\\\"</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token boolean\\\">None</span><span class=\\\"token punctuation\\\">,</span> n_classes<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n\\n<span class=\\\"token comment\\\"># Create model</span>\\n<span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">multilayer_perceptron</span><span class=\\\"token punctuation\\\">(</span>x<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n    <span class=\\\"token comment\\\"># Hidden layer with RELU activation</span>\\n    layer_1 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>add<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>matmul<span class=\\\"token punctuation\\\">(</span>x<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'h1'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'b1'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n    layer_1 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>nn<span class=\\\"token punctuation\\\">.</span>relu<span class=\\\"token punctuation\\\">(</span>layer_1<span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># Hidden layer with RELU activation</span>\\n    layer_2 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>add<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>matmul<span class=\\\"token punctuation\\\">(</span>layer_1<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'h2'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'b2'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n    layer_2 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>nn<span class=\\\"token punctuation\\\">.</span>relu<span class=\\\"token punctuation\\\">(</span>layer_2<span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># Output layer with linear activation</span>\\n    out_layer <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>matmul<span class=\\\"token punctuation\\\">(</span>layer_2<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">+</span> biases<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">]</span>\\n    <span class=\\\"token keyword\\\">return</span> out_layer\\n\\n<span class=\\\"token comment\\\"># Store layers weight &amp; bias</span>\\nweights <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">{</span>\\n    <span class=\\\"token string\\\">'h1'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_input<span class=\\\"token punctuation\\\">,</span> n_hidden_1<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'h2'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_1<span class=\\\"token punctuation\\\">,</span> n_hidden_2<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_2<span class=\\\"token punctuation\\\">,</span> n_classes<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token punctuation\\\">}</span>\\nbiases <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">{</span>\\n    <span class=\\\"token string\\\">'b1'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_1<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'b2'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_2<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_classes<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token punctuation\\\">}</span>\\n\\n<span class=\\\"token comment\\\"># Construct model</span>\\npred <span class=\\\"token operator\\\">=</span> multilayer_perceptron<span class=\\\"token punctuation\\\">(</span>x<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Define loss and optimizer</span>\\ncost <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>reduce_mean<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>nn<span class=\\\"token punctuation\\\">.</span>softmax_cross_entropy_with_logits<span class=\\\"token punctuation\\\">(</span>logits<span class=\\\"token operator\\\">=</span>pred<span class=\\\"token punctuation\\\">,</span> labels<span class=\\\"token operator\\\">=</span>y<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\noptimizer <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>train<span class=\\\"token punctuation\\\">.</span>AdamOptimizer<span class=\\\"token punctuation\\\">(</span>learning_rate<span class=\\\"token operator\\\">=</span>learning_rate<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>minimize<span class=\\\"token punctuation\\\">(</span>cost<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Initializing the variables</span>\\ninit <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>global_variables_initializer<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Launch the graph</span>\\n<span class=\\\"token keyword\\\">with</span> tf<span class=\\\"token punctuation\\\">.</span>Session<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token keyword\\\">as</span> sess<span class=\\\"token punctuation\\\">:</span>\\n    sess<span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span>init<span class=\\\"token punctuation\\\">)</span>\\n\\n    <span class=\\\"token comment\\\"># Training cycle</span>\\n    <span class=\\\"token keyword\\\">for</span> epoch <span class=\\\"token keyword\\\">in</span> <span class=\\\"token builtin\\\">range</span><span class=\\\"token punctuation\\\">(</span>training_epochs<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        avg_cost <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>\\n        <span class=\\\"token comment\\\"># total_batch = int(mnist.train.num_examples/batch_size)</span>\\n        <span class=\\\"token comment\\\"># # Loop over all batches</span>\\n        <span class=\\\"token comment\\\"># for i in range(total_batch):</span>\\n        <span class=\\\"token comment\\\">#     batch_x, batch_y = mnist.train.next_batch(batch_size)</span>\\n        <span class=\\\"token comment\\\">#     # Run optimization op (backprop) and cost op (to get loss value)</span>\\n        <span class=\\\"token comment\\\">#     _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,</span>\\n        <span class=\\\"token comment\\\">#                                                   y: batch_y})</span>\\n        <span class=\\\"token comment\\\">#     # Compute average loss</span>\\n        <span class=\\\"token comment\\\">#     avg_cost += c / total_batch</span>\\n        <span class=\\\"token comment\\\"># # Display logs per epoch step</span>\\n        _<span class=\\\"token punctuation\\\">,</span> c <span class=\\\"token operator\\\">=</span> sess<span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>optimizer<span class=\\\"token punctuation\\\">,</span> cost<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span> feed_dict<span class=\\\"token operator\\\">=</span><span class=\\\"token punctuation\\\">{</span>x<span class=\\\"token punctuation\\\">:</span> training_input<span class=\\\"token punctuation\\\">,</span> y<span class=\\\"token punctuation\\\">:</span> training_output<span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span>\\n        avg_cost <span class=\\\"token operator\\\">+=</span> c\\n        <span class=\\\"token keyword\\\">if</span> epoch <span class=\\\"token operator\\\">%</span> display_step <span class=\\\"token operator\\\">==</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">:</span>\\n            <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"Epoch:\\\"</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'%04d'</span> <span class=\\\"token operator\\\">%</span> <span class=\\\"token punctuation\\\">(</span>epoch<span class=\\\"token operator\\\">+</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">\\\"cost=\\\"</span><span class=\\\"token punctuation\\\">,</span> \\\\\\n                <span class=\\\"token string\\\">\\\"{:.9f}\\\"</span><span class=\\\"token punctuation\\\">.</span><span class=\\\"token builtin\\\">format</span><span class=\\\"token punctuation\\\">(</span>avg_cost<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"Optimization Finished!\\\"</span><span class=\\\"token punctuation\\\">)</span>\\n\\n    <span class=\\\"token comment\\\"># Test model</span>\\n    correct_prediction <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>equal<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>argmax<span class=\\\"token punctuation\\\">(</span>pred<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> tf<span class=\\\"token punctuation\\\">.</span>argmax<span class=\\\"token punctuation\\\">(</span>y<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># Calculate accuracy</span>\\n    accuracy <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>reduce_mean<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>cast<span class=\\\"token punctuation\\\">(</span>correct_prediction<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">\\\"float\\\"</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"Accuracy:\\\"</span><span class=\\\"token punctuation\\\">,</span> accuracy<span class=\\\"token punctuation\\\">.</span><span class=\\\"token builtin\\\">eval</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">{</span>x<span class=\\\"token punctuation\\\">:</span> testing_input<span class=\\\"token punctuation\\\">,</span> y<span class=\\\"token punctuation\\\">:</span> testing_output<span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span></code></pre>\\n      </div>\",\"timeToRead\":2,\"excerpt\":\"\",\"frontmatter\":{\"title\":\"Softmax with Tensorflow\",\"cover\":null},\"fields\":{\"nextTitle\":\"Softmax Implementation\",\"nextSlug\":\"/machine-learning/notes/softmax/\",\"prevTitle\":\"Singel Layer Perceptron (SGD)\",\"prevSlug\":\"/machine-learning/notes/single-layer-perceptron/\",\"slug\":\"/machine-learning/notes/softmax-tf/\",\"modifiedTime\":\"9-6-2018, 1:38\"}},\"allDirectory\":null,\"allFile\":null},\"pathContext\":{\"slug\":\"/machine-learning/notes/softmax-tf/\",\"slugTrim\":\"machine-learning/notes/softmax-tf\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---machine-learning-notes-softmax-tf-892435dfd84428ee0046.js","module.exports = {\"data\":{\"markdownRemark\":{\"html\":\"<div class=\\\"gatsby-highlight\\\">\\n      <pre class=\\\"language-python\\\"><code class=\\\"language-python\\\"><span class=\\\"token comment\\\"># Author: Fajar UN</span>\\n\\n<span class=\\\"token comment\\\"># Import MNIST data</span>\\n<span class=\\\"token comment\\\"># from tensorflow.examples.tutorials.mnist import input_data</span>\\n<span class=\\\"token comment\\\"># mnist = input_data.read_data_sets(\\\"/tmp/data/\\\", one_hot=True)</span>\\n\\n<span class=\\\"token keyword\\\">import</span> pandas <span class=\\\"token keyword\\\">as</span> pd\\ndf <span class=\\\"token operator\\\">=</span> pd<span class=\\\"token punctuation\\\">.</span>get_dummies<span class=\\\"token punctuation\\\">(</span>pd<span class=\\\"token punctuation\\\">.</span>read_csv<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">'iris.csv'</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> columns<span class=\\\"token operator\\\">=</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'species'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>sample<span class=\\\"token punctuation\\\">(</span>frac<span class=\\\"token operator\\\">=</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span>\\nlabel_cols <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'species_setosa'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'species_versicolor'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'species_virginica'</span><span class=\\\"token punctuation\\\">]</span>\\n\\n\\nsplit_val <span class=\\\"token operator\\\">=</span> <span class=\\\"token builtin\\\">int</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token builtin\\\">len</span><span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">*</span> <span class=\\\"token number\\\">0.8</span><span class=\\\"token punctuation\\\">)</span>\\ntraining_input <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'sepal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'sepal_width'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_width'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">:</span>split_val<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\ntesting_input <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'sepal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'sepal_width'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_length'</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'petal_width'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span>split_val<span class=\\\"token punctuation\\\">:</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\ntraining_output <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span>label_cols<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span><span class=\\\"token punctuation\\\">:</span>split_val<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\ntesting_output <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">(</span>df<span class=\\\"token punctuation\\\">[</span>label_cols<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">[</span>split_val<span class=\\\"token punctuation\\\">:</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>as_matrix<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token keyword\\\">import</span> tensorflow <span class=\\\"token keyword\\\">as</span> tf\\n\\n<span class=\\\"token comment\\\"># Parameters</span>\\nlearning_rate <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">0.001</span>\\ntraining_epochs <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">1000</span>\\nbatch_size <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">100</span>\\ndisplay_step <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">100</span>\\n\\n<span class=\\\"token comment\\\"># Network Parameters</span>\\nn_hidden_1 <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">6</span> <span class=\\\"token comment\\\"># 1st layer number of features</span>\\nn_hidden_2 <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">12</span> <span class=\\\"token comment\\\"># 2nd layer number of features</span>\\nn_input <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">4</span> <span class=\\\"token comment\\\"># MNIST data input (img shape: 28*28)</span>\\nn_classes <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">3</span> <span class=\\\"token comment\\\"># MNIST total classes (0-9 digits)</span>\\n\\n<span class=\\\"token comment\\\"># tf Graph input</span>\\nx <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>placeholder<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"float\\\"</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token boolean\\\">None</span><span class=\\\"token punctuation\\\">,</span> n_input<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\ny <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>placeholder<span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"float\\\"</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token punctuation\\\">[</span><span class=\\\"token boolean\\\">None</span><span class=\\\"token punctuation\\\">,</span> n_classes<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n\\n\\n<span class=\\\"token comment\\\"># Create model</span>\\n<span class=\\\"token keyword\\\">def</span> <span class=\\\"token function\\\">multilayer_perceptron</span><span class=\\\"token punctuation\\\">(</span>x<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n    <span class=\\\"token comment\\\"># Hidden layer with RELU activation</span>\\n    layer_1 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>add<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>matmul<span class=\\\"token punctuation\\\">(</span>x<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'h1'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'b1'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n    layer_1 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>nn<span class=\\\"token punctuation\\\">.</span>relu<span class=\\\"token punctuation\\\">(</span>layer_1<span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># Hidden layer with RELU activation</span>\\n    layer_2 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>add<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>matmul<span class=\\\"token punctuation\\\">(</span>layer_1<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'h2'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'b2'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span>\\n    layer_2 <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>nn<span class=\\\"token punctuation\\\">.</span>relu<span class=\\\"token punctuation\\\">(</span>layer_2<span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># Output layer with linear activation</span>\\n    out_layer <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>matmul<span class=\\\"token punctuation\\\">(</span>layer_2<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token operator\\\">+</span> biases<span class=\\\"token punctuation\\\">[</span><span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">]</span>\\n    <span class=\\\"token keyword\\\">return</span> out_layer\\n\\n<span class=\\\"token comment\\\"># Store layers weight &amp; bias</span>\\nweights <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">{</span>\\n    <span class=\\\"token string\\\">'h1'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_input<span class=\\\"token punctuation\\\">,</span> n_hidden_1<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'h2'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_1<span class=\\\"token punctuation\\\">,</span> n_hidden_2<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_2<span class=\\\"token punctuation\\\">,</span> n_classes<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token punctuation\\\">}</span>\\nbiases <span class=\\\"token operator\\\">=</span> <span class=\\\"token punctuation\\\">{</span>\\n    <span class=\\\"token string\\\">'b1'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_1<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'b2'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_hidden_2<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span>\\n    <span class=\\\"token string\\\">'out'</span><span class=\\\"token punctuation\\\">:</span> tf<span class=\\\"token punctuation\\\">.</span>Variable<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>random_normal<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>n_classes<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n<span class=\\\"token punctuation\\\">}</span>\\n\\n<span class=\\\"token comment\\\"># Construct model</span>\\npred <span class=\\\"token operator\\\">=</span> multilayer_perceptron<span class=\\\"token punctuation\\\">(</span>x<span class=\\\"token punctuation\\\">,</span> weights<span class=\\\"token punctuation\\\">,</span> biases<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Define loss and optimizer</span>\\ncost <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>reduce_mean<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>nn<span class=\\\"token punctuation\\\">.</span>softmax_cross_entropy_with_logits<span class=\\\"token punctuation\\\">(</span>logits<span class=\\\"token operator\\\">=</span>pred<span class=\\\"token punctuation\\\">,</span> labels<span class=\\\"token operator\\\">=</span>y<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\noptimizer <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>train<span class=\\\"token punctuation\\\">.</span>AdamOptimizer<span class=\\\"token punctuation\\\">(</span>learning_rate<span class=\\\"token operator\\\">=</span>learning_rate<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">.</span>minimize<span class=\\\"token punctuation\\\">(</span>cost<span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Initializing the variables</span>\\ninit <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>global_variables_initializer<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span>\\n\\n<span class=\\\"token comment\\\"># Launch the graph</span>\\n<span class=\\\"token keyword\\\">with</span> tf<span class=\\\"token punctuation\\\">.</span>Session<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">)</span> <span class=\\\"token keyword\\\">as</span> sess<span class=\\\"token punctuation\\\">:</span>\\n    sess<span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span>init<span class=\\\"token punctuation\\\">)</span>\\n\\n    <span class=\\\"token comment\\\"># Training cycle</span>\\n    <span class=\\\"token keyword\\\">for</span> epoch <span class=\\\"token keyword\\\">in</span> <span class=\\\"token builtin\\\">range</span><span class=\\\"token punctuation\\\">(</span>training_epochs<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">:</span>\\n        avg_cost <span class=\\\"token operator\\\">=</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">.</span>\\n        <span class=\\\"token comment\\\"># total_batch = int(mnist.train.num_examples/batch_size)</span>\\n        <span class=\\\"token comment\\\"># # Loop over all batches</span>\\n        <span class=\\\"token comment\\\"># for i in range(total_batch):</span>\\n        <span class=\\\"token comment\\\">#     batch_x, batch_y = mnist.train.next_batch(batch_size)</span>\\n        <span class=\\\"token comment\\\">#     # Run optimization op (backprop) and cost op (to get loss value)</span>\\n        <span class=\\\"token comment\\\">#     _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,</span>\\n        <span class=\\\"token comment\\\">#                                                   y: batch_y})</span>\\n        <span class=\\\"token comment\\\">#     # Compute average loss</span>\\n        <span class=\\\"token comment\\\">#     avg_cost += c / total_batch</span>\\n        <span class=\\\"token comment\\\"># # Display logs per epoch step</span>\\n        _<span class=\\\"token punctuation\\\">,</span> c <span class=\\\"token operator\\\">=</span> sess<span class=\\\"token punctuation\\\">.</span>run<span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">[</span>optimizer<span class=\\\"token punctuation\\\">,</span> cost<span class=\\\"token punctuation\\\">]</span><span class=\\\"token punctuation\\\">,</span> feed_dict<span class=\\\"token operator\\\">=</span><span class=\\\"token punctuation\\\">{</span>x<span class=\\\"token punctuation\\\">:</span> training_input<span class=\\\"token punctuation\\\">,</span> y<span class=\\\"token punctuation\\\">:</span> training_output<span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span>\\n        avg_cost <span class=\\\"token operator\\\">+=</span> c\\n        <span class=\\\"token keyword\\\">if</span> epoch <span class=\\\"token operator\\\">%</span> display_step <span class=\\\"token operator\\\">==</span> <span class=\\\"token number\\\">0</span><span class=\\\"token punctuation\\\">:</span>\\n            <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"Epoch:\\\"</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">'%04d'</span> <span class=\\\"token operator\\\">%</span> <span class=\\\"token punctuation\\\">(</span>epoch<span class=\\\"token operator\\\">+</span><span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">\\\"cost=\\\"</span><span class=\\\"token punctuation\\\">,</span> \\\\\\n                <span class=\\\"token string\\\">\\\"{:.9f}\\\"</span><span class=\\\"token punctuation\\\">.</span><span class=\\\"token builtin\\\">format</span><span class=\\\"token punctuation\\\">(</span>avg_cost<span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"Optimization Finished!\\\"</span><span class=\\\"token punctuation\\\">)</span>\\n\\n    <span class=\\\"token comment\\\"># Test model</span>\\n    correct_prediction <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>equal<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>argmax<span class=\\\"token punctuation\\\">(</span>pred<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">,</span> tf<span class=\\\"token punctuation\\\">.</span>argmax<span class=\\\"token punctuation\\\">(</span>y<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token number\\\">1</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token comment\\\"># Calculate accuracy</span>\\n    accuracy <span class=\\\"token operator\\\">=</span> tf<span class=\\\"token punctuation\\\">.</span>reduce_mean<span class=\\\"token punctuation\\\">(</span>tf<span class=\\\"token punctuation\\\">.</span>cast<span class=\\\"token punctuation\\\">(</span>correct_prediction<span class=\\\"token punctuation\\\">,</span> <span class=\\\"token string\\\">\\\"float\\\"</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span>\\n    <span class=\\\"token keyword\\\">print</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token string\\\">\\\"Accuracy:\\\"</span><span class=\\\"token punctuation\\\">,</span> accuracy<span class=\\\"token punctuation\\\">.</span><span class=\\\"token builtin\\\">eval</span><span class=\\\"token punctuation\\\">(</span><span class=\\\"token punctuation\\\">{</span>x<span class=\\\"token punctuation\\\">:</span> testing_input<span class=\\\"token punctuation\\\">,</span> y<span class=\\\"token punctuation\\\">:</span> testing_output<span class=\\\"token punctuation\\\">}</span><span class=\\\"token punctuation\\\">)</span><span class=\\\"token punctuation\\\">)</span></code></pre>\\n      </div>\",\"timeToRead\":2,\"excerpt\":\"\",\"frontmatter\":{\"title\":\"Softmax with Tensorflow\",\"cover\":null},\"fields\":{\"nextTitle\":\"Softmax Implementation\",\"nextSlug\":\"/machine-learning/notes/softmax/\",\"prevTitle\":\"Singel Layer Perceptron (SGD)\",\"prevSlug\":\"/machine-learning/notes/single-layer-perceptron/\",\"slug\":\"/machine-learning/notes/softmax-tf/\",\"modifiedTime\":\"9-6-2018, 1:38\"}},\"allDirectory\":null,\"allFile\":null},\"pathContext\":{\"slug\":\"/machine-learning/notes/softmax-tf/\",\"slugTrim\":\"machine-learning/notes/softmax-tf\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/machine-learning-notes-softmax-tf.json\n// module id = 714\n// module chunks = 252309606565646"],"sourceRoot":""}